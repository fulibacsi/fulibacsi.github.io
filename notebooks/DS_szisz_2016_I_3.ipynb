{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Data Science @ SzISz Part III.\n",
    "## Data Transformation\n",
    "\n",
    "### Table of contents\n",
    "- <a href=\"#What-is-Data-Transformation?\">Theory</a>\n",
    "- <a href=\"#Numerical-Features\">Numerical Transformations</a>\n",
    "- <a href=\"#Textual-Features\">Textual Transformations</a>\n",
    "- <a href=\"#Pipelines-and-FeatureUnions\">Pipelines and Feature Unions</a>\n",
    "\n",
    "## What is Data Transformation?\n",
    "During data transformation the goal is to prepare the data to be usable in the modelling steps. These transformations include normalization, standardization, text processing, generating complex features from basic ones, or any kind of data mapping.\n",
    "\n",
    "_\"...a data transformation converts a set of data values from the data format of a source data system into the data format of a destination data system._\n",
    "\n",
    "_Data transformation can be divided into two steps:_\n",
    "1. _data mapping maps data elements from the source data system to the destination data system and captures any transformation that must occur_\n",
    "2. _code generation that creates the actual transformation program\"_\n",
    "from: <a href=\"https://en.wikipedia.org/wiki/Data_transformation\">Wikipedia</a>\n",
    "\n",
    "## Why is it important?\n",
    "\n",
    "Most of the models are sensitive to data, so you must transform it into a more desired format. Unfortunately the data you start with is usually in terrible shape:\n",
    "\n",
    "- It has missing values\n",
    "- It is full of outliers\n",
    "- The data is distorted by noise\n",
    "- The features are in different scales\n",
    "- The features are correlated/redundant/uninformative\n",
    "\n",
    "\n",
    "## Tools\n",
    "\n",
    "- scaling/binarizing\n",
    "- normalizing/standardizing\n",
    "- outlier detecting\n",
    "- filtering\n",
    "- mathematical transformations\n",
    "- representational changes\n",
    "- etc.\n",
    "\n",
    "---\n",
    "\n",
    "## Imports and custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_missing(X, random_state=42):\n",
    "    \"\"\"Randomly replace values in an np.ndarray with np.nan, np.inf or -np.inf.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : np.ndarray\n",
    "        Target array in which the values will be randomly replaced.\n",
    "        \n",
    "    random_state : int\n",
    "        Random seed initializing the pseudo-random number generator.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    X' : np.ndarray\n",
    "        Array with nans and infs.\n",
    "    \"\"\"\n",
    "    custom_random = np.random.RandomState(random_state)\n",
    "    mask = custom_random.rand(*X.shape)\n",
    "    mask[mask < 0.9] = 1.\n",
    "    mask[(mask >= 0.9) & (mask < 0.95)] = np.nan\n",
    "    mask[(mask >= 0.95) & (mask < 0.975)] = np.inf\n",
    "    mask[(mask >= 0.975) & (mask < 1.)] = -np.inf\n",
    "    return X * mask\n",
    "\n",
    "def change_scale(X, factor=5., columns=1, random_state=42):\n",
    "    \"\"\"Randomly multiply a column or columns in an np.ndarray.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : np.ndarray\n",
    "        Target array in which a column will be multiplied.\n",
    "    \n",
    "    factor : float\n",
    "        The multiplication factor\n",
    "        \n",
    "    columns : int or array-like\n",
    "        Number of columns to multiply if int type, else the column indices which are multiplied.\n",
    "        \n",
    "    random_state : int\n",
    "        Random seed initializing the pseudo-random number generator.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    X' : np.ndarray\n",
    "        Array with multiplied valued columns.\n",
    "    \"\"\"\n",
    "    custom_random = np.random.RandomState(random_state)\n",
    "    X_comma = X.copy()\n",
    "    rows, cols = X.shape\n",
    "    if not isinstance(columns, collections.Iterable):\n",
    "        columns = [custom_random.randint(cols) for _ in xrange(columns)]\n",
    "    for column in columns:\n",
    "        X_comma[:, column] *= factor\n",
    "    return X_comma\n",
    "\n",
    "def add_outlier(X, value=10, num=1, random_state=42):\n",
    "    \"\"\"Add a specified number of outliers to the input np.ndarray.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : np.ndarray\n",
    "        Target array in which the outliers will be inputted.\n",
    "    \n",
    "    value : float\n",
    "        The value of the outlier.\n",
    "        \n",
    "    num : int\n",
    "        The number of outliers to be placed.\n",
    "        \n",
    "    random_state : int\n",
    "        Random seed initializing the pseudo-random number generator.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    X' : np.ndarray\n",
    "        Array with outliers.\n",
    "    \"\"\"\n",
    "    custom_random = np.random.RandomState(random_state)\n",
    "    X_comma = X.copy()\n",
    "    rows, cols = X_comma.shape\n",
    "    for _ in xrange(num):\n",
    "        row = custom_random.randint(rows)\n",
    "        col = custom_random.randint(cols)\n",
    "        X_comma[row, col] += value\n",
    "    \n",
    "    return X_comma\n",
    "\n",
    "def binarize(X, bins=2):\n",
    "    \"\"\"Binarize matrix elements based on the values.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : np.ndarray\n",
    "        Target array to binarize.\n",
    "        \n",
    "    bins : int\n",
    "        Number of values to appear in the binarized matrix.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    X_comma : np.ndarray\n",
    "        Binarized matrix\n",
    "    \"\"\"\n",
    "    X_comma = X.copy()\n",
    "    delims = np.linspace(X_comma.min(), X_comma.max(), bins+1)\n",
    "    delims = zip(delims, delims[1:])\n",
    "    for bin_val, (start, end) in enumerate(delims):\n",
    "        X_comma[(start <= X) & (X <= end)] = bin_val\n",
    "    return X_comma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_row(axis, df, column, labels):\n",
    "    \"\"\"Scatterplot a column against all of the columns in a pd.DataFrame.\n",
    "    Colors the points based on labels.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    axis : iterable of matplotlib.axes\n",
    "        List of target axis.\n",
    "        \n",
    "    df : pd.DataFrame\n",
    "        DataFrame to plot.\n",
    "        \n",
    "    column : str\n",
    "        The DataFrame's column to plot against.\n",
    "        \n",
    "    labels : iterable\n",
    "        The labels for the rows in the DataFrame.\n",
    "    \"\"\"\n",
    "    for i, col_ax in zip(df.columns.values, axis):\n",
    "        col_ax.scatter(df[column], df[i], c=labels, cmap='magma')\n",
    "\n",
    "def gridplot(df, labels, columns=None, figsize=(12,12)):\n",
    "    \"\"\"Generate a gridplot over a pd.DataFrame's columns.\n",
    "    If the columns parameter is specified, plot against that column(s).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame to plot.\n",
    "        \n",
    "    labels : iterable\n",
    "        The labels for the rows in the DataFrame.\n",
    "        \n",
    "    columns : None, pd.DataFrame columnname, iterable over pd.DF colnames\n",
    "        The columns to plot against. If None, plot every column against every column.\n",
    "        \n",
    "    figsize : tuple of ints\n",
    "        The size of the resulting plot.\n",
    "    \"\"\"\n",
    "    if columns is None:\n",
    "        columns = df.columns.values\n",
    "    if not isinstance(columns, collections.Iterable):\n",
    "        columns = [columns]\n",
    "        \n",
    "    ncols = len(df.columns)\n",
    "    nrows = len(columns)\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, sharex=\"col\", sharey=\"row\", figsize=figsize)\n",
    "    ax = ax.reshape(nrows, ncols)\n",
    "\n",
    "    for col, row_ax in zip(columns, ax):\n",
    "        plot_row(axis=row_ax, df=df, column=col, labels=labels)\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data, labels = make_classification(n_features=10, random_state=42)\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Numerical features\n",
    "\n",
    "\n",
    "### <a href=\"http://pandas.pydata.org/pandas-docs/stable/missing_data.html\">missing values</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing = pd.DataFrame(input_missing(data))\n",
    "missing.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dropped = missing.dropna()\n",
    "dropped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filled = missing.fillna(value=0)\n",
    "filled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "interpolated = missing.interpolate(method='nearest')\n",
    "interpolated.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a href=\"http://pandas.pydata.org/pandas-docs/stable/missing_data.html#values-considered-missing\">infinite values</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('mode.use_inf_as_null', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dropped = missing.dropna(axis=0)\n",
    "dropped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filled = missing.fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "interpolated = missing.interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a href=\"http://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling\">different scales</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaled = pd.DataFrame(change_scale(data))\n",
    "scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gridplot(scaled, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gridplot(scaled, labels, columns=6, figsize=(20,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled[[6]] = scaler.fit_transform(scaled[[6]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gridplot(scaled, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(), robust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not now. More about this topic in the next issue. Cough-cough-<a href=\"http://scikit-learn.org/stable/modules/preprocessing.html#scaling-data-with-outliers\" style=\"color: black; text-decoration: none; cursor: default;\">PCA</a>-cough.\n",
    "\n",
    "### <a href=\"http://scikit-learn.org/stable/modules/preprocessing.html#scaling-data-with-outliers\">outliers</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outlied = pd.DataFrame(add_outlier(data, value=100))\n",
    "outlied.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gridplot(outlied, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a href=\"https://www.youtube.com/watch?v=MymAUbwSX80\" style=\"color: black; text-decoration: none; cursor: default;\">ACT NOW!</a> Write a function which removes the outlier from a dataframe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_outlier(df):\n",
    "    \"\"\"Removes the outlier from the given dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        The dataframe with outliers.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    df' : pd.DataFrame\n",
    "        The cleaned dataframe.\n",
    "    \"\"\"\n",
    "    # TODO: YOUR MAGIC\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a href=\"http://scikit-learn.org/stable/modules/preprocessing.html#feature-binarization\">binarization</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "binarizer = Binarizer()\n",
    "binarizer.fit_transform(df)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textual Transformations\n",
    "\n",
    "### <a href=\"http://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features\">Categorical values</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categorical = binarize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### <a href=\"http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html#bags-of-words\">Bag of words</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a href=\"http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html#from-occurrences-to-frequencies\">Tf-Idf</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines and FeatureUnions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
