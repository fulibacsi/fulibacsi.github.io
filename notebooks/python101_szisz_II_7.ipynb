{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python 101 @ SzISz VII."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Today: Web Scraping II."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Act I: scrape the hungarian tenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get some nasty data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# store some general data\n",
    "BASE_URI = '../data/'\n",
    "BASE_URL = 'http://kozbeszerzes.ceu.hu'\n",
    "kozgep_suburl = '/entity/t/10950676.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# download raw data\n",
    "kozgep_response = requests.get(BASE_URL + kozgep_suburl)\n",
    "print kozgep_response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print what did we get\n",
    "soup = BeautifulSoup(kozgep_response.content)\n",
    "print soup.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# iterate through the tenders\n",
    "# beautifulsoup can parse xmls too\n",
    "for tender in soup.find('all_tenders_won').findAll('tender'):\n",
    "    print BASE_URL + tender['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# parse the first tender\n",
    "tender_response = requests.get(\n",
    "    BASE_URL + soup.find('all_tenders_won').find('tender')['url']\n",
    ")\n",
    "if not tender_response.status_code == 200:\n",
    "    print 'Tender download failed!'\n",
    "else:\n",
    "    tender_soup = BeautifulSoup(tender_response.content)\n",
    "    print tender_soup.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a function, and get the needed information out of the xml\n",
    "def get_tenders(base_url, sub_url):\n",
    "    response = requests.get(base_url + sub_url)\n",
    "    if not response.status_code == 200:\n",
    "        print 'Download failed!'\n",
    "    else:\n",
    "        won_tenders = [['Year', 'Value', 'Desc']] # init with headers\n",
    "        soup = BeautifulSoup(response.content)\n",
    "        for tender in soup.find('all_tenders_won').findAll('tender'):\n",
    "            tender_response = requests.get(base_url + tender['url'])\n",
    "            if not tender_response.status_code == 200:\n",
    "                print 'Tender download failed!'\n",
    "            else:\n",
    "                tender_soup = BeautifulSoup(tender_response.content)\n",
    "                won_tenders.append([\n",
    "                    tender_soup.find('tender')['year'],\n",
    "                    tender_soup.find('tender')['estimated_value'],\n",
    "                    '\"' + tender_soup.find('tender')['subject'] + '\"' # we use \" to make sure that the data is wrapped\n",
    "                ])\n",
    "        return won_tenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write a save function\n",
    "# since we have hungarian text, we need to encode our characters in UTF-8\n",
    "# and unfortunately csv module does not support that\n",
    "import codecs\n",
    "def save_results(filename, tenders):\n",
    "    with codecs.open(filename, 'w', 'utf-8') as output:\n",
    "        for tender in tenders:\n",
    "            output.write(u';'.join(tender) + u'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write a main function\n",
    "def main():\n",
    "    save_results(BASE_URI + 'kozgep.csv', get_tenders(BASE_URL, kozgep_suburl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# execute\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intermission: Creating a standalone script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Intermission\n",
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo(\"O0wOD9TWynM\", autoplay=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new text file with .py extension! You can specify the filename.\n",
    "Start it with:  \n",
    "    `# encoding: utf-8`  \n",
    "then copy-paste:\n",
    "    - the imports, \n",
    "    - the global variables \n",
    "    - the three functions\n",
    "and insert the following two lines into the end of the file:  \n",
    "`if __name__ == '__main__':  \n",
    "     main()`  \n",
    "Save it, and now you can execute this script by invoking:  \n",
    "    `python your_specified_filename.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can even import your newly created script:\n",
    "import myscript # use your filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get it's contents\n",
    "dir(myscript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print its variables\n",
    "print myscript.BASE_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use its functions\n",
    "tenders = myscript.get_tenders(myscript.BASE_URL, myscript.kozgep_suburl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myscript.save_results(BASE_URI + 'kozgep1.csv', tenders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Act II: Disguise yourself!\n",
    "\n",
    "Let's pretend to be a browser instead of a script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "USER_AGENTS = [\n",
    "    # Chrome\n",
    "    'Mozilla/5.0 (Windows NT 6.2; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1667.0 Safari/537.36',\n",
    "    # Firefox\n",
    "    'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:25.0) Gecko/20100101 Firefox/25.0',\n",
    "    # Opera\n",
    "    'Opera/9.80 (Windows NT 6.0) Presto/2.12.388 Version/12.14',\n",
    "    # Safari\n",
    "    'Mozilla/5.0 (iPad; CPU OS 6_0 like Mac OS X) AppleWebKit/536.26 (KHTML, like Gecko) Version/6.0 Mobile/10A5355d Safari/8536.25',\n",
    "    # Internet Explorer, probably a good idea to leave this one out...\n",
    "    'Mozilla/5.0 (compatible; MSIE 10.6; Windows NT 6.1; Trident/5.0; InfoPath.2; SLCC1; .NET CLR 3.0.4506.2152; .NET CLR 3.5.30729; .NET CLR 2.0.50727) 3gpp-gba UNTRUSTED/1.0',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write a wrapper function to handle the user-agent string\n",
    "import random\n",
    "def get_header(agents):\n",
    "    return {'User-agent': random.choice(agents)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the main articles from index.hu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'http://index.hu'\n",
    "index_response = requests.get(url, headers=get_header(USER_AGENTS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# study the skeleton of the site\n",
    "soup = BeautifulSoup(index_response.content)\n",
    "print soup.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the \"front page\"\n",
    "index_main = soup.find('section', {'class': 'blokk hajtas-felett dupla-vezeto-blokk cimlap-blokk-index blokk_uj-blokk saved'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print the basics about the main articles\n",
    "for article in index_main.findAll('article'):\n",
    "    print ''\n",
    "    # article image if exists\n",
    "    if article.find('img'):\n",
    "        print '[', article.find('img').get('src'), ']'\n",
    "    # title\n",
    "    print article.find('h1', {'class': 'cikkcim'}).getText()\n",
    "    # link\n",
    "    print '<', article.find('h1', {'class': 'cikkcim'}).find('a').get('href'), '>'\n",
    "    # promo text if exists\n",
    "    if article.find('p', {'class': 'ajanlo'}):\n",
    "        print article.find('p', {'class': 'ajanlo'}).getText()\n",
    "    print '-' * 79"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the article texts, and the list of images for each \"main\" article!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "articles = []\n",
    "for article in index_main.findAll('article'):\n",
    "    article_response = requests.get(\n",
    "        article.find('h1', {'class': 'cikkcim'}).find('a').get('href'),\n",
    "        headers=get_header(USER_AGENTS)\n",
    "    )\n",
    "    soup = BeautifulSoup(article_response.content)\n",
    "    article_container = soup.find('div', {'class':'cikk-torzs-container'})\n",
    "    if article_container:\n",
    "        title = article.find('h1', {'class': 'cikkcim'}).getText()\n",
    "        text = u'\\n'.join([p.getText() for p in article_container.findAll('p')])\n",
    "        images = [url.get('src') for url in article_container.findAll('img')]\n",
    "        articles.append([title, text, images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for article in articles:\n",
    "    print ''\n",
    "    print 'Title:', article[0]\n",
    "    print 'Text:', article[1]\n",
    "    print 'Images:'\n",
    "    for img in article[2]:\n",
    "        print img\n",
    "    print '-' * 79"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Act: Your turn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a script called `youtube.py`, in which you create an object called RelatedTube.\n",
    "It has an attribute: `base_url` (youtube's base url)\n",
    "It has three functions: `init`, `get`, and `set`\n",
    "\n",
    "Init:\n",
    "    - Arguments: (`self` and) `youtube_video_id`\n",
    "    - Output: -\n",
    "    - Workflow: set the `self.video` to `youtube_video_id`\n",
    "Get:\n",
    "    - Arguments: `self`\n",
    "    - Output: the links to the related videos\n",
    "    - Workflow: \n",
    "        * get the `self.video` page\n",
    "        * parse it for the related links\n",
    "        * return them in a list\n",
    "Set:\n",
    "    - Arguments: (`self` and) `youtube_video_id`\n",
    "    - Output: -\n",
    "    - Workflow: set the `self.video` to `youtube_video_id`\n",
    "Don't forget to hide your a**!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test the script\n",
    "import youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "related = youtube.RelatedTube('zkxqRthhwIs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for video in related.get():\n",
    "    print video"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
