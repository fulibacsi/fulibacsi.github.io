{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Data Science @ SzISz Part VII.\n",
    "## Grand Finale:<br> Model Selection, Pipeline building, and Custom Sklearn Nodes \n",
    "\n",
    "### Table of contents\n",
    "- <a href=\"#What-is-Model-Selection?\">Model Selection Theory</a>\n",
    "- <a href=\"#Cross-Validation\">Cross Validation</a>\n",
    "    - <a href=\"#Grid-Search-Cross-Validation\">Randomized Search Cross Validation</a>\n",
    "    - <a href=\"#Randomized-Search-Cross-Validation\">Randomized Search Cross Validation</a>\n",
    "- <a href=\"#Building-Pipelines\">Building Pipelines</a>\n",
    "- <a href=\"#Building-a-Custom-Sklearn-Node\">Building a Custom Scikit-learn Node</a>\n",
    "    \n",
    "\n",
    "## What is Model Selection?\n",
    "_\"Model selection is the task of selecting a statistical model from a set of candidate models, given data. In the simplest cases, a pre-existing set of data is considered.\"_ from: <a href=\"https://en.wikipedia.org/wiki/Model_selection\">Wiki</a>  \n",
    "In this context we also include the process of finding the optimal hyperparameters.\n",
    "\n",
    "## Why is it important?\n",
    "To find the optimal solution to a given problem, one must train several models with similar predictive/exploratory power and select the simplest one. This process includes selecting models and finding optimal hyperparameters which is a time consuming and tedious work when done by hand. We use automatized solutions to overcome this problem, save time, and yield better results.\n",
    "\n",
    "## Tools\n",
    "- Grid Search\n",
    "- Randomized search\n",
    "- etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "np.random.seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a href=\"http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation\">Cross Validation</a>\n",
    "\n",
    "In order to select an optimal model, first one must be able to measure a model's/pipe's accuracy.  \n",
    "\n",
    "First, one must select a valid metric for the model. In sklearn, the basic validation metric is accuracy score in case of classification, and $r^{2}$ for regression. Altough, several other metrics can be selected from <a href=\"http://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules\">this</a> list.\n",
    "\n",
    "_\"Learning the parameters of a prediction function and testing it on the same data is a methodological mistake: a model that would just repeat the labels of the samples that it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen data. This situation is called overfitting.\"_ [1]. To overcome this problem, one must split the data to __training__ and __test__ dataset; train the model on the train dataset, then measure the precision on the test dataset.\n",
    "\n",
    "However different splits can produce different outcomes, so this process must be repeated several times to give a good approximation to the examined model's accuracy. This process is called __Cross Validation__ and there are <a href=\"http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators\">different strategies</a> to make these splits.\n",
    "\n",
    "A simple model can yield different solutions to the same data based on its hyperparameters so multiple models must be trained to select the ideal hyperparamter settings. Cross Validation gives a good approximation to a trained model's accuracy, but additional methods are required to select the ideal hyperparameters. \n",
    "\n",
    "[1] <a href=\"http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-evaluating-estimator-performance\">Scikit-learn 0.17.1 documentation</a>\n",
    "\n",
    "\n",
    "### Grid Search Cross Validation\n",
    "Grid search is a method which generates a parameter grid from a list of settings, and measure the input model's accuracy in every setting using cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Intermission:\n",
    "## Building Pipelines\n",
    "A Quick reminder how to build sklearn pipes and how to access their parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/tutorial/statistical_inference/putting_together.html\n",
    "# http://scikit-learn.org/stable/auto_examples/exercises/plot_cv_digits.html#example-exercises-plot-cv-digits-py\n",
    "steps = [\n",
    "    ('dummy', pass)\n",
    "]\n",
    "pipe = Pipeline(steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe.fit_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe.set_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__end of intermission__\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/modules/grid_search.html\n",
    "# http://scikit-learn.org/stable/tutorial/statistical_inference/model_selection.html#grid-search-and-cross-validated-estimators\n",
    "param_grid = [\n",
    "    {},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=pipe, param_grid=param_grid,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Search Cross Validation\n",
    "Randomized search randomly generate a fixed number of hyperparameter setups. It selects the parameters from the provided parameter parameter ranges and then measures them with cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/auto_examples/model_selection/randomized_search.html\n",
    "param_dist = [\n",
    "    ()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search = RandomizedSearchCV(estimator=pipe,param_distributions=param_dist, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Custom Sklearn Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin, ClusterMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyEstimator(BaseEstimator, TransformerMixin):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyClassifier(BaseEstimator, ClassifierMixin):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyClustering(BaseEstimator, ClusterMixin):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
